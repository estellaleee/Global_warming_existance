{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis for Existance of Global Warming\n",
    "\n",
    "Training dataset: \n",
    "- Sentiment Analysis – Global Warming/Climate Change\n",
    "-  https://www.figure-eight.com/data-for-everyone/ \n",
    "- Contributors evaluated tweets for belief in the existence of global warming or climate change. The possible answers were “Yes” if the tweet suggests global warming is occurring, “No” if the tweet suggests global warming is not occurring, and “I can’t tell” if the tweet is ambiguous or unrelated to global warming. We also provide a confidence score for the classification of each tweet.\n",
    "\n",
    "All codes inspired by Vicky Qian: https://gist.github.com/vickyqian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"earthday.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-23 04:15:15</td>\n",
       "      <td>b'#EarthDay19 remember that we\\xe2\\x80\\x99re p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-23 04:15:12</td>\n",
       "      <td>b'RT @NatGeo: \\xe2\\x80\\x9cThe countries that a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-23 04:15:12</td>\n",
       "      <td>b\"We might die, and I'm not going to lie to yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-23 04:15:10</td>\n",
       "      <td>b'RT @SanjayBajpai65: In the next 30 yrs, thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-23 04:14:38</td>\n",
       "      <td>b'The amount of shade being thrown on this Ear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time                                            Content\n",
       "0  2019-04-23 04:15:15  b'#EarthDay19 remember that we\\xe2\\x80\\x99re p...\n",
       "1  2019-04-23 04:15:12  b'RT @NatGeo: \\xe2\\x80\\x9cThe countries that a...\n",
       "2  2019-04-23 04:15:12  b\"We might die, and I'm not going to lie to yo...\n",
       "3  2019-04-23 04:15:10  b'RT @SanjayBajpai65: In the next 30 yrs, thre...\n",
       "4  2019-04-23 04:14:38  b'The amount of shade being thrown on this Ear..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={0:\"Time\", 1:\"Content\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33443, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def unicode_csv_reader(unicode_csv_data, dialect=csv.excel, **kwargs):\n",
    "    # csv.py doesn't do Unicode; encode temporarily as UTF-8:\n",
    "    csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),\n",
    "                            dialect=dialect, **kwargs)\n",
    "    for row in csv_reader:\n",
    "        # decode UTF-8 back to Unicode, cell by cell:\n",
    "        yield [unicode(cell, 'utf-8') for cell in row]\n",
    "\n",
    "def utf_8_encoder(unicode_csv_data):\n",
    "    for line in unicode_csv_data:\n",
    "        yield line.encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"global_warming_train.csv\", encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6089, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Preprocess tweets\n",
    "def processTweet2(tweet):\n",
    "    # process the tweets\n",
    "\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "###get stopword list\n",
    "def getStopWordList(stopWordListFileName):\n",
    "    #read the stopwords file and build a list\n",
    "    stopWords = []\n",
    "    stopWords.append('AT_USER')\n",
    "    stopWords.append('URL')\n",
    "\n",
    "    fp = open(stopWordListFileName, 'r')\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        word = line.strip()\n",
    "        stopWords.append(word)\n",
    "        line = fp.readline()\n",
    "    fp.close()\n",
    "    return stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = []\n",
    "\n",
    "st = open('stopword.txt', 'r')\n",
    "stopWords = getStopWordList('stopword.txt')\n",
    "\n",
    "\n",
    "def replaceTwoOrMore(s):\n",
    "    #look for 2 or more repetitions of character and replace with the character itself\n",
    "    pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
    "    return pattern.sub(r\"\\1\\1\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureVector(tweet):\n",
    "    featureVector = []\n",
    "    #split tweet into words\n",
    "    words = tweet.split()\n",
    "    for w in words:\n",
    "        #replace two or more with two occurrences\n",
    "        w = replaceTwoOrMore(w)\n",
    "        #strip punctuation\n",
    "        w = w.strip('\\'\"?,.')\n",
    "        #check if the word stats with an alphabet\n",
    "        val = re.search(r\"^[a-zA-Z][a-zA-Z0-9]*$\", w)\n",
    "        #ignore if it is a stop word\n",
    "        if(w in stopWords or val is None):\n",
    "            continue\n",
    "        else:\n",
    "            featureVector.append(w.lower())\n",
    "    return featureVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'<title>(.*)</title>', re.UNICODE)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.compile('<title>(.*)</title>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "###load gb sentiment training data \n",
    "    \n",
    "gbtrain = pd.read_csv(\"global_warming_train.csv\", encoding =\"ISO-8859-1\")\n",
    "tweets = []\n",
    "featureList = []\n",
    "for i in range(len(gbtrain)):\n",
    "    sentiment = gbtrain['existence'][i]\n",
    "    tweet = gbtrain['tweet'][i]\n",
    "    processedTweet = processTweet2(tweet)\n",
    "    featureVector = getFeatureVector(processedTweet)\n",
    "    featureList.extend(featureVector)\n",
    "    tweets.append((featureVector, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet):\n",
    "    tweet_words = set(tweet)\n",
    "    features = {}\n",
    "    for word in featureList:\n",
    "        features['contains(%s)' % word] = (word in tweet_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove featureList duplicates\n",
    "featureList = list(set(featureList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "training_set = nltk.classify.util.apply_features(extract_features, tweets)\n",
    "# Train the classifier Naive Bayes Classifier\n",
    "NBClassifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "#df is a dataframe containing all the tweets\n",
    "df['sentiment'] = df['Content'].apply(lambda tweet: NBClassifier.classify(extract_features(getFeatureVector(processTweet2(tweet)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-23 04:15:15</td>\n",
       "      <td>b'#EarthDay19 remember that we\\xe2\\x80\\x99re p...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-23 04:15:12</td>\n",
       "      <td>b'RT @NatGeo: \\xe2\\x80\\x9cThe countries that a...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-23 04:15:12</td>\n",
       "      <td>b\"We might die, and I'm not going to lie to yo...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-23 04:15:10</td>\n",
       "      <td>b'RT @SanjayBajpai65: In the next 30 yrs, thre...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-23 04:14:38</td>\n",
       "      <td>b'The amount of shade being thrown on this Ear...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-04-23 04:14:31</td>\n",
       "      <td>b'RT @SteveSGoddard: @JonathanFranki3 @luvkit ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-04-23 04:14:19</td>\n",
       "      <td>b'@ChandlerLovric @40Sauce @realCHVSE @lildick...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-04-23 04:14:18</td>\n",
       "      <td>b'RT @SteveSGoddard: @JonathanFranki3 @luvkit ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-04-23 04:14:05</td>\n",
       "      <td>b'More damned blush violets for coral reptiles...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-04-23 04:13:52</td>\n",
       "      <td>b'@charliekirk11 @realDonaldTrump Beautiful. G...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-04-23 04:13:32</td>\n",
       "      <td>b'RT @AZSenateDems: Happy #EarthDay! Climate c...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-04-23 04:13:07</td>\n",
       "      <td>b'@CanalesFredrick @Ilhan In 2 short years Tru...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-04-23 04:13:02</td>\n",
       "      <td>b\"With global warming we may avoid that crazy ...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-04-23 04:12:56</td>\n",
       "      <td>b'@singaporedavid1 @MrKRudd Say global warming...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-04-23 04:12:39</td>\n",
       "      <td>b'RT @alexbruesewitz: 1970: We\\xe2\\x80\\x99ll b...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-04-23 04:12:39</td>\n",
       "      <td>b'RT @alexbruesewitz: 1970: We\\xe2\\x80\\x99ll b...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-04-23 04:12:35</td>\n",
       "      <td>b'RT @C_doc_911: Trump applied for a permit fo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-04-23 04:12:26</td>\n",
       "      <td>b\"RT @theUNCLEdaily: LNP Senate candidate accu...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-04-23 04:12:07</td>\n",
       "      <td>b'Tornadoes-Global warming\\n\\nHurricanes-Clima...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-04-23 04:12:07</td>\n",
       "      <td>b'@wwwdotjkdotcom the point of this tweet was ...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-04-23 04:12:05</td>\n",
       "      <td>b\"@EstherPassaris I admire the pains you go th...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-04-23 04:12:01</td>\n",
       "      <td>b'RT @SilkenLaumann: My kids know more about g...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-04-23 04:11:44</td>\n",
       "      <td>b'Complete use of NOx and NP is Essential for ...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-04-23 04:11:36</td>\n",
       "      <td>b'RT @darrengrimes_: In 1989 the UN warned, \\x...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-04-23 04:11:34</td>\n",
       "      <td>b'RT @brock_tingley: I seriously don\\xe2\\x80\\x...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-04-23 04:11:21</td>\n",
       "      <td>b'RT @SteveSGoddard: @JonathanFranki3 @luvkit ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-04-23 04:11:13</td>\n",
       "      <td>b'@JonathanFranki3 @luvkit @ScottAdamsSays I u...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-04-23 04:10:58</td>\n",
       "      <td>b'RT @alexbruesewitz: 1970: We\\xe2\\x80\\x99ll b...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-04-23 04:10:55</td>\n",
       "      <td>b'RT @NatGeo: \\xe2\\x80\\x9cThe countries that a...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-04-23 04:10:17</td>\n",
       "      <td>b'Stupid argument #2\\nGlobal warming give real...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33413</th>\n",
       "      <td>2019-04-20 13:07:29</td>\n",
       "      <td>b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33414</th>\n",
       "      <td>2019-04-20 13:07:28</td>\n",
       "      <td>b'People need to listen to David Attenborough....</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33415</th>\n",
       "      <td>2019-04-20 13:07:25</td>\n",
       "      <td>b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33416</th>\n",
       "      <td>2019-04-20 13:07:11</td>\n",
       "      <td>b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33417</th>\n",
       "      <td>2019-04-20 13:07:09</td>\n",
       "      <td>b'RT @ProfPCDoherty: \"Enough cowardice...it\\'s...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33418</th>\n",
       "      <td>2019-04-20 13:07:01</td>\n",
       "      <td>b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33419</th>\n",
       "      <td>2019-04-20 13:06:53</td>\n",
       "      <td>b'RT @AOCpress: I turned on all my TVs in my h...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33420</th>\n",
       "      <td>2019-04-20 13:06:46</td>\n",
       "      <td>b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33421</th>\n",
       "      <td>2019-04-20 13:06:26</td>\n",
       "      <td>b\"RT @SulaymanAli: @TheSpurrShow @LBC Here is ...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33422</th>\n",
       "      <td>2019-04-20 13:06:26</td>\n",
       "      <td>b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33423</th>\n",
       "      <td>2019-04-20 13:06:25</td>\n",
       "      <td>b'RT @buterabrazy: for y\\xe2\\x80\\x99all laughi...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33424</th>\n",
       "      <td>2019-04-20 13:06:23</td>\n",
       "      <td>b'@tia_martineau IM NOT LYING, male astronaut ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33425</th>\n",
       "      <td>2019-04-20 13:06:18</td>\n",
       "      <td>b\"RT @BNicholas: Well, on the plus side, globa...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33426</th>\n",
       "      <td>2019-04-20 13:06:10</td>\n",
       "      <td>b'Evolution of a Liberal \"tested\" Buzzwords ag...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33427</th>\n",
       "      <td>2019-04-20 13:05:58</td>\n",
       "      <td>b'Me stressing about global warming and pollut...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33428</th>\n",
       "      <td>2019-04-20 13:05:52</td>\n",
       "      <td>b'RT @cultnasa: lil dicky didn\\xe2\\x80\\x99t ma...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33429</th>\n",
       "      <td>2019-04-20 13:05:34</td>\n",
       "      <td>b'RT @fossilheads: #ExtinctionRebellion are pr...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33430</th>\n",
       "      <td>2019-04-20 13:05:31</td>\n",
       "      <td>b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33431</th>\n",
       "      <td>2019-04-20 13:05:05</td>\n",
       "      <td>b'@liamyoung Carbon credits bring Lakshmi Mitt...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33432</th>\n",
       "      <td>2019-04-20 13:04:59</td>\n",
       "      <td>b\"@MrRaceBannon Dosen't China make the most po...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33433</th>\n",
       "      <td>2019-04-20 13:04:57</td>\n",
       "      <td>b\"RT @Seasaver: The wrong people are in charge...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33434</th>\n",
       "      <td>2019-04-20 13:04:50</td>\n",
       "      <td>b'@liamyoung Global warming underpins a multi ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33435</th>\n",
       "      <td>2019-04-20 13:04:47</td>\n",
       "      <td>b'RT @SayWhenLA: They moved goalposts to \"muh ...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33436</th>\n",
       "      <td>2019-04-20 13:04:30</td>\n",
       "      <td>b\"RT @Seasaver: The wrong people are in charge...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33437</th>\n",
       "      <td>2019-04-20 13:04:29</td>\n",
       "      <td>b'Global warming the best thing to happen to t...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33438</th>\n",
       "      <td>2019-04-20 13:04:26</td>\n",
       "      <td>b'RT @Brilliant_Ads: Politicians discussing gl...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33439</th>\n",
       "      <td>2019-04-20 13:04:20</td>\n",
       "      <td>b'RT @buterabrazy: for y\\xe2\\x80\\x99all laughi...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33440</th>\n",
       "      <td>2019-04-20 13:04:20</td>\n",
       "      <td>b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33441</th>\n",
       "      <td>2019-04-20 13:03:51</td>\n",
       "      <td>b\"RT @BNicholas: Well, on the plus side, globa...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33442</th>\n",
       "      <td>2019-04-20 13:03:39</td>\n",
       "      <td>b'RT @pee_after_sex: Nobody: \\nMy parents seei...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33443 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Time                                            Content  \\\n",
       "0      2019-04-23 04:15:15  b'#EarthDay19 remember that we\\xe2\\x80\\x99re p...   \n",
       "1      2019-04-23 04:15:12  b'RT @NatGeo: \\xe2\\x80\\x9cThe countries that a...   \n",
       "2      2019-04-23 04:15:12  b\"We might die, and I'm not going to lie to yo...   \n",
       "3      2019-04-23 04:15:10  b'RT @SanjayBajpai65: In the next 30 yrs, thre...   \n",
       "4      2019-04-23 04:14:38  b'The amount of shade being thrown on this Ear...   \n",
       "5      2019-04-23 04:14:31  b'RT @SteveSGoddard: @JonathanFranki3 @luvkit ...   \n",
       "6      2019-04-23 04:14:19  b'@ChandlerLovric @40Sauce @realCHVSE @lildick...   \n",
       "7      2019-04-23 04:14:18  b'RT @SteveSGoddard: @JonathanFranki3 @luvkit ...   \n",
       "8      2019-04-23 04:14:05  b'More damned blush violets for coral reptiles...   \n",
       "9      2019-04-23 04:13:52  b'@charliekirk11 @realDonaldTrump Beautiful. G...   \n",
       "10     2019-04-23 04:13:32  b'RT @AZSenateDems: Happy #EarthDay! Climate c...   \n",
       "11     2019-04-23 04:13:07  b'@CanalesFredrick @Ilhan In 2 short years Tru...   \n",
       "12     2019-04-23 04:13:02  b\"With global warming we may avoid that crazy ...   \n",
       "13     2019-04-23 04:12:56  b'@singaporedavid1 @MrKRudd Say global warming...   \n",
       "14     2019-04-23 04:12:39  b'RT @alexbruesewitz: 1970: We\\xe2\\x80\\x99ll b...   \n",
       "15     2019-04-23 04:12:39  b'RT @alexbruesewitz: 1970: We\\xe2\\x80\\x99ll b...   \n",
       "16     2019-04-23 04:12:35  b'RT @C_doc_911: Trump applied for a permit fo...   \n",
       "17     2019-04-23 04:12:26  b\"RT @theUNCLEdaily: LNP Senate candidate accu...   \n",
       "18     2019-04-23 04:12:07  b'Tornadoes-Global warming\\n\\nHurricanes-Clima...   \n",
       "19     2019-04-23 04:12:07  b'@wwwdotjkdotcom the point of this tweet was ...   \n",
       "20     2019-04-23 04:12:05  b\"@EstherPassaris I admire the pains you go th...   \n",
       "21     2019-04-23 04:12:01  b'RT @SilkenLaumann: My kids know more about g...   \n",
       "22     2019-04-23 04:11:44  b'Complete use of NOx and NP is Essential for ...   \n",
       "23     2019-04-23 04:11:36  b'RT @darrengrimes_: In 1989 the UN warned, \\x...   \n",
       "24     2019-04-23 04:11:34  b'RT @brock_tingley: I seriously don\\xe2\\x80\\x...   \n",
       "25     2019-04-23 04:11:21  b'RT @SteveSGoddard: @JonathanFranki3 @luvkit ...   \n",
       "26     2019-04-23 04:11:13  b'@JonathanFranki3 @luvkit @ScottAdamsSays I u...   \n",
       "27     2019-04-23 04:10:58  b'RT @alexbruesewitz: 1970: We\\xe2\\x80\\x99ll b...   \n",
       "28     2019-04-23 04:10:55  b'RT @NatGeo: \\xe2\\x80\\x9cThe countries that a...   \n",
       "29     2019-04-23 04:10:17  b'Stupid argument #2\\nGlobal warming give real...   \n",
       "...                    ...                                                ...   \n",
       "33413  2019-04-20 13:07:29  b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...   \n",
       "33414  2019-04-20 13:07:28  b'People need to listen to David Attenborough....   \n",
       "33415  2019-04-20 13:07:25  b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...   \n",
       "33416  2019-04-20 13:07:11  b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...   \n",
       "33417  2019-04-20 13:07:09  b'RT @ProfPCDoherty: \"Enough cowardice...it\\'s...   \n",
       "33418  2019-04-20 13:07:01  b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...   \n",
       "33419  2019-04-20 13:06:53  b'RT @AOCpress: I turned on all my TVs in my h...   \n",
       "33420  2019-04-20 13:06:46  b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...   \n",
       "33421  2019-04-20 13:06:26  b\"RT @SulaymanAli: @TheSpurrShow @LBC Here is ...   \n",
       "33422  2019-04-20 13:06:26  b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...   \n",
       "33423  2019-04-20 13:06:25  b'RT @buterabrazy: for y\\xe2\\x80\\x99all laughi...   \n",
       "33424  2019-04-20 13:06:23  b'@tia_martineau IM NOT LYING, male astronaut ...   \n",
       "33425  2019-04-20 13:06:18  b\"RT @BNicholas: Well, on the plus side, globa...   \n",
       "33426  2019-04-20 13:06:10  b'Evolution of a Liberal \"tested\" Buzzwords ag...   \n",
       "33427  2019-04-20 13:05:58  b'Me stressing about global warming and pollut...   \n",
       "33428  2019-04-20 13:05:52  b'RT @cultnasa: lil dicky didn\\xe2\\x80\\x99t ma...   \n",
       "33429  2019-04-20 13:05:34  b'RT @fossilheads: #ExtinctionRebellion are pr...   \n",
       "33430  2019-04-20 13:05:31  b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...   \n",
       "33431  2019-04-20 13:05:05  b'@liamyoung Carbon credits bring Lakshmi Mitt...   \n",
       "33432  2019-04-20 13:04:59  b\"@MrRaceBannon Dosen't China make the most po...   \n",
       "33433  2019-04-20 13:04:57  b\"RT @Seasaver: The wrong people are in charge...   \n",
       "33434  2019-04-20 13:04:50  b'@liamyoung Global warming underpins a multi ...   \n",
       "33435  2019-04-20 13:04:47  b'RT @SayWhenLA: They moved goalposts to \"muh ...   \n",
       "33436  2019-04-20 13:04:30  b\"RT @Seasaver: The wrong people are in charge...   \n",
       "33437  2019-04-20 13:04:29  b'Global warming the best thing to happen to t...   \n",
       "33438  2019-04-20 13:04:26  b'RT @Brilliant_Ads: Politicians discussing gl...   \n",
       "33439  2019-04-20 13:04:20  b'RT @buterabrazy: for y\\xe2\\x80\\x99all laughi...   \n",
       "33440  2019-04-20 13:04:20  b'RT @GretaThunberg: \\xe2\\x80\\x9cEmissions fro...   \n",
       "33441  2019-04-20 13:03:51  b\"RT @BNicholas: Well, on the plus side, globa...   \n",
       "33442  2019-04-20 13:03:39  b'RT @pee_after_sex: Nobody: \\nMy parents seei...   \n",
       "\n",
       "      sentiment  \n",
       "0             Y  \n",
       "1             Y  \n",
       "2             N  \n",
       "3             Y  \n",
       "4             Y  \n",
       "5             N  \n",
       "6             Y  \n",
       "7             N  \n",
       "8             N  \n",
       "9             N  \n",
       "10            Y  \n",
       "11            Y  \n",
       "12            Y  \n",
       "13            N  \n",
       "14            Y  \n",
       "15            Y  \n",
       "16          NaN  \n",
       "17            N  \n",
       "18            Y  \n",
       "19            Y  \n",
       "20            Y  \n",
       "21            N  \n",
       "22            Y  \n",
       "23            Y  \n",
       "24            N  \n",
       "25            N  \n",
       "26            Y  \n",
       "27            Y  \n",
       "28            Y  \n",
       "29            Y  \n",
       "...         ...  \n",
       "33413         Y  \n",
       "33414         Y  \n",
       "33415         Y  \n",
       "33416         Y  \n",
       "33417         Y  \n",
       "33418         Y  \n",
       "33419         Y  \n",
       "33420         Y  \n",
       "33421         Y  \n",
       "33422         Y  \n",
       "33423         N  \n",
       "33424         N  \n",
       "33425         N  \n",
       "33426         Y  \n",
       "33427         Y  \n",
       "33428         N  \n",
       "33429         Y  \n",
       "33430         Y  \n",
       "33431         Y  \n",
       "33432         Y  \n",
       "33433         Y  \n",
       "33434         N  \n",
       "33435         N  \n",
       "33436         Y  \n",
       "33437         Y  \n",
       "33438         Y  \n",
       "33439         N  \n",
       "33440         Y  \n",
       "33441         N  \n",
       "33442         N  \n",
       "\n",
       "[33443 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"earthday_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22845, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"sentiment\"]==\"Y\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8308, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"sentiment\"]==\"N\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"sentiment\"]==\"Yes\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"] = df[\"sentiment\"].replace({\"Yes\":\"Y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time            0\n",
       "Content         0\n",
       "sentiment    2225\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31218, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04:15:15</td>\n",
       "      <td>b'#EarthDay19 remember that we\\xe2\\x80\\x99re p...</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019-04-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04:15:12</td>\n",
       "      <td>b'RT @NatGeo: \\xe2\\x80\\x9cThe countries that a...</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019-04-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04:15:12</td>\n",
       "      <td>b\"We might die, and I'm not going to lie to yo...</td>\n",
       "      <td>N</td>\n",
       "      <td>2019-04-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04:15:10</td>\n",
       "      <td>b'RT @SanjayBajpai65: In the next 30 yrs, thre...</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019-04-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04:14:38</td>\n",
       "      <td>b'The amount of shade being thrown on this Ear...</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019-04-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time                                            Content sentiment  \\\n",
       "0  04:15:15  b'#EarthDay19 remember that we\\xe2\\x80\\x99re p...         Y   \n",
       "1  04:15:12  b'RT @NatGeo: \\xe2\\x80\\x9cThe countries that a...         Y   \n",
       "2  04:15:12  b\"We might die, and I'm not going to lie to yo...         N   \n",
       "3  04:15:10  b'RT @SanjayBajpai65: In the next 30 yrs, thre...         Y   \n",
       "4  04:14:38  b'The amount of shade being thrown on this Ear...         Y   \n",
       "\n",
       "         Date  \n",
       "0  2019-04-23  \n",
       "1  2019-04-23  \n",
       "2  2019-04-23  \n",
       "3  2019-04-23  \n",
       "4  2019-04-23  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"], df[\"Time\"] = df[\"Time\"].str.split(' ').str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthday = df[df[\"Date\"] == \"2019-04-22\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthday.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthday_final = copy.deepcopy(earthday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthday_final = earthday_final[[\"Time\", \"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthday_final.to_csv(\"twitter_earthday.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv3",
   "language": "python",
   "name": "myenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
